{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8283c96f",
   "metadata": {},
   "source": [
    "**Table of Contents 目录**\n",
    "***\n",
    "\n",
    "\n",
    "***I. Statistics 统计***\n",
    "***\n",
    "**1. Probability& Calculus 概率和微积分**\n",
    "- Bayes' Theorem 贝叶斯定理\n",
    "- Definition of Random Variable 随机变量定义\n",
    "- Discrete Random Variable 离散随机变量\n",
    "- Continuous Random Variable 连续随机变量\n",
    "- Gradient 梯度\n",
    "\n",
    "**2. Terms 概念**\n",
    "- Random Variable Expectation& Variance Formula 随机变量期望和方差公式\n",
    "- Sample Mean 样本平均值\n",
    "- Sample Variance 样本方差\n",
    "- Estimator 估计量\n",
    "- Confidence Interval 置信区间\n",
    "\n",
    "***\n",
    "***II. A/B testing A/B测试***\n",
    "***\n",
    "\n",
    "**1. Hypothesis testing basics 假设检验基础**\n",
    "\n",
    "**2. hypothesis testing procedure 假设检验程序**\n",
    "\n",
    "**3. experiment design workflow 实验设计工作流程**\n",
    "\n",
    "**4. advanced topic 进阶主题**\n",
    "\n",
    "\n",
    "***\n",
    "***III. Machine Learning 机器学习***\n",
    "***\n",
    "\n",
    "**1. Linear Regression 线性回归**\n",
    "\n",
    "**2. Logistics Regression & Softmax Regression & Generalized Linear Model** \n",
    "逻辑回归模型，Softmax回归模型，广义线性模型\n",
    "\n",
    "**3. Model Bias Variance Tradeoff 模型偏差方差权衡**\n",
    "- Definition of Overfitting 过拟合定义\n",
    "- Model Space 模型空间\n",
    "- Definition of Bias and Variance 偏差和方差定义\n",
    "- Bias and Variance Tradeoffs 偏差和方差权衡\n",
    "\n",
    "**4. Regularization 正则化**\n",
    "\n",
    "**5. Model Evaluation 模型评估**\n",
    "- Introduction to Cross Validation 交叉验证简介\n",
    "- Example - Cross Validation for Model Selection 示例 - 模型选择的交叉验证\n",
    "- Hyper-parameter Tuning 超参数调优\n",
    "- Data Leakage Problem 数据泄露问题\n",
    "- Confusion Matrix 混淆矩阵\n",
    "- Accuracy, Precision and Recall 准确度、精确度和召回率\n",
    "- Receiver Operating Characteristic (ROC) Curve 曲线ROC\n",
    "- Area Under the Curve (AUC) 曲线下面积AUC\n",
    "\n",
    "**6. Decision Tree Model 决策树模型**\n",
    "- Introduction of Decision Tree 决策树介绍\n",
    "- Entropy & Gini Impurity 熵和基尼不纯度\n",
    "- Decision Tree Algorithm 决策树算法\n",
    "- Pruning 剪枝\n",
    "\n",
    "**7. Random Forest Model 随机森林模型**\n",
    "- Ensemble Learning 集成学习\n",
    "- Random Forest Algorithm 随机森林算法\n",
    "- Feature Importance 特征重要性\n",
    "- Out-of-bag Error 包外误差\n",
    "\n",
    "**8. Boosting Model: adaboost, gradient boosting, XGBoost Boosting 模型：adaboost、梯度提升、XGBoost**\n",
    "- Introduction to Boosting Method 方法介绍- Boosting\n",
    "- Additive Modeling 可加模型\n",
    "- Discrete AdaBoost 离散AdaBoost\n",
    "- Shrinkage 收缩\n",
    "- Gradient Boosting Machine - Overview 梯度提升机 - 概述\n",
    "- Gradient Boosting Machine - Details & Example 梯度提升机 - 详细信息和示例\n",
    "- Introduction to XGBoost 简介- XGBoost\n",
    "- XGBoost - Loss Function Details 损失函数细节- XGBoost\n",
    "\n",
    "**9. K-nearest Neighbors Model K近邻模型**\n",
    "- K-nearest Neighbors Algorithm k近邻算法\n",
    "- KNN Code 模型代码KNN\n",
    "- Approximate Nearest Neighbors Algorithm 近似k近邻算法\n",
    "\n",
    "**10. K-means Model K均值聚类模型**\n",
    "- K-means Algorithm 算法K-means\n",
    "- K-means Optimization 优化K-means\n",
    "- Find the Optimal K 找到最佳K\n",
    "- K-means ++ algorithsm(k-means clustering) K均值聚类算法\n",
    "\n",
    "**11. Linear Algebra 线性代数**\n",
    "- Matrix & Linear Transformation 矩阵和线性变换\n",
    "- Eigenvector, Eigenvalue and Singular Value 特征向量、特征值和奇异值\n",
    "- Eigendecomposition 特征分解\n",
    "- Covariance Matrix 协方差矩阵\n",
    "- Geometry of Linear Transformation - Basic Concepts 线性变换几何 - 基本概念\n",
    "- Geometry of Linear Transformation - Change of Basis 线性变换几何 - 基础变化\n",
    "\n",
    "**12. PCA: Principal Component Analysis 主成分分析PCA**\n",
    "- PCA Formula 公式讲解PCA\n",
    "- PCA Algorithm 算法步骤PCA\n",
    "- PCA Code 模型代码PCA\n",
    "\n",
    "\n",
    "***\n",
    "***IV. Deep Learning 深度学习***\n",
    "***\n",
    "\n",
    "**1. backpropagation 反向传播演算法**\n",
    "\n",
    "**2. basics& optimization 基础知识和优化**\n",
    "\n",
    "**3. convolutional neural network 卷积神经网络**\n",
    "\n",
    "**4. recurrent neural networks 循环神经网络** \n",
    "\n",
    "**5. Recommendation system design 推荐系统设计**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2b0f939",
   "metadata": {},
   "source": [
    "-- x-mind?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a1b0d",
   "metadata": {},
   "source": [
    "## Jupyter keyboard shortcuts: Command + Shift + P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cdd5be",
   "metadata": {},
   "source": [
    "# *I. Statistics 统计*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79266416",
   "metadata": {},
   "source": [
    "## Q1: What are the advantages and disadvantages of using sample mean as an estimator?样本均值作为估计量的优点和缺点是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe81b0b",
   "metadata": {},
   "source": [
    "1. advantages:\n",
    "\n",
    "i. Unbiasedness: The sample mean is an unbiased estimator of the population mean, which means that, on average, it will give an accurate estimate of the true population mean.\n",
    "\n",
    "—> sample mean是population mean的无偏估计\n",
    "\n",
    "ii. Consistency: As the sample size increases, the sample mean converges to the population mean, and variance decreases. This property ensures that with larger sample sizes, the sample mean becomes a more accurate estimator.\n",
    "\n",
    "随着数据量增加，sample mean的variance以线性速度不断减小，精确度不断提高。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ffb1e",
   "metadata": {},
   "source": [
    "2. Disadvantages:\n",
    "\n",
    "i. Sensitivity to outliers: The sample mean is sensitive to extreme values or outliers in the data. Outliers can disproportionately influence the estimate of the mean, leading to biased results.\n",
    "\n",
    "ii. Sample dependence: The sample mean relies solely on the available sample data and does not take into account the underlying population distribution. It may not accurately estimate the population mean if the sample is not representative of the population.\n",
    "\n",
    "iii. Sample size requirements: The sample mean performs well when the sample size is large enough, but it may not provide accurate estimates with small sample sizes. The precision of the estimate depends on the sample size, and small samples may lead to larger estimation errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebe5a9",
   "metadata": {},
   "source": [
    "## Q2: What is a 95% confidence interval? 95%置信区间是指什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1bdc6c",
   "metadata": {},
   "source": [
    "In statistics, a 95% confidence interval means that if we were to repeat the sampling procedure many times and calculate confidence intervals, approximately 95% of those intervals would contain the true population parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1187eb9a",
   "metadata": {},
   "source": [
    "## Q3: Explain P-value definition. 解释P-value定义。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688d637",
   "metadata": {},
   "source": [
    "P value is the probability of obtaining as or more extreme results than the current observation, under the null hypothesis. \n",
    "\n",
    "① it is a probability \n",
    "\n",
    "② it is calculated under the null hypothesis\n",
    "\n",
    "③ as or more extreme results\n",
    "\n",
    "p-value 是计算值，本身也是随机变量，随机性来源于sample data 随机性\n",
    "\n",
    "significance level α不是计算出来的值，是预先设定的threshold\n",
    "\n",
    "α 确定 HT中 p-value小到多少才能满足要求，一般定为0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77565f7e",
   "metadata": {},
   "source": [
    "## Q4: How can we verify if the training data and validation data follow the same distribution? 如何确认训练数据和验证数据符合相同的分布？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec6d64",
   "metadata": {},
   "source": [
    "## Q5: How can we verify the randomness of missing values in our training dataset? 如何确认在训练数据集丢失值的随机性?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba1cc4",
   "metadata": {},
   "source": [
    "## Q6: Describe the procedure of hypothesis testing. 描述假设检验程序。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b6b5e",
   "metadata": {},
   "source": [
    "Hypothesis testing is a way to assess the plausibility of an assumption regarding a population parameter by using sample data; help figure out the odds that results happened by chance\n",
    "\n",
    "假设检验是一种通过使用样本数据来评估关于总体参数的假设的合理性的方法； 帮助找出结果偶然发生的几率。\n",
    "\n",
    "i. 使用HT时因为可以控制样本随机性造成的错误。\n",
    "\n",
    "ii. 找到结果发生的几率\n",
    "\n",
    "① form the hypothesis 提出假设\n",
    "\n",
    "② construct the estimator and test statistics 预测量 μ se z\n",
    "\n",
    "③ obtain the distribution of test statistics under the null hypothesis 分布\n",
    "\n",
    "④calculate p-value P值\n",
    "\n",
    "⑤draw conclusion (reject or not reject null hypothesis) 结论\n",
    "\n",
    "※设计hypothesis的原则是，试图reject null hypothesis, confirm alternative hypothesis。这是无罪推定，先假定无罪，再通过足够的理由推翻假定，证明有罪。这样做可以控制false positive。\n",
    "\n",
    "H0：零假设是两者没有差异，观察到的差异是由于抽样或实验误差\n",
    "\n",
    "Ha：备择假设是试图证明的有意思结果，是两者有差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086da467",
   "metadata": {},
   "source": [
    "## Q7: What’s the difference between p-value, type I error rate and significance level, Z-score? P值、I 类错误率和显著性水平、Z-score之间有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ecd191",
   "metadata": {},
   "source": [
    "i. Type I error = false positive = significance level = α\n",
    "\n",
    "= P(reject H0| H0 is true) = P( p value < significance level | H0 is true)\n",
    "\n",
    "the probability of rejecting the null hypothesis given that the null hypothesis is true.\n",
    "\n",
    "the probability of having type I error is type I error rate α\n",
    "\n",
    "零假设正确却拒绝了零假设，hypothesis testing犯错的概率\n",
    "\n",
    "误判为阳性\n",
    "\n",
    "ii. Type II error = false negative = β ＝1 - power\n",
    "\n",
    "the probability of having type II error is type II error rate β\n",
    "\n",
    "power is the probability that an experiment will flag a real change as statistically significant\n",
    "\n",
    "零假设错误却接受了零假设，hypothesis testing犯错的概率\n",
    "\n",
    "误判为阴性\n",
    "\n",
    "iii. Type I error rate 和Type II error rate是此消彼长的\n",
    "\n",
    "iv. Z-score:\n",
    "\n",
    "对于sample mean estimator, 为后续计算方便，将其normalization，得到服从N(0, 1)分布的Z-score：\n",
    "\n",
    "σ sample mean = σ population / n\n",
    "\n",
    "Z = (X - μ) / σ sample mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513d60b1",
   "metadata": {},
   "source": [
    "## Q8: How to deal with the tradeoff between Type I error rate and Type II error rate? (ie. How to set the significance level?) 如何处理I类错误率和II类错误率之间的权衡? (如何设定显著性水平)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8ae93d",
   "metadata": {},
   "source": [
    "大部分情况下，Type I error 比Type II error严重，比如法院定罪，互联网公司判定新产品效果\n",
    "\n",
    "type I error: 本来无罪却判为有罪，本来新旧产品无差异却判定新产品有效，所以更严重\n",
    "\n",
    "方法：\n",
    "\n",
    "①choose a relatively lower significance level; 设定低的α\n",
    "\n",
    "②increase sample size( collect more data) to decrease type II error rate. 提高样本数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896b7326",
   "metadata": {},
   "source": [
    "## Q9: Given a fixed-size sample data and 0.05 significance level, shall we reject the null hypothesis if the p-value is 0.049? 当固定样本量数据和显著性水平为0.05，如果p值为0.05，应该拒绝原假设吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc461d8",
   "metadata": {},
   "source": [
    "it depends\n",
    "\n",
    "讨论use case中type I error 和type II error的严重程度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbf091d",
   "metadata": {},
   "source": [
    "Q: \n",
    "\n",
    "**precision& recall 查准率&查全率**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f0329e",
   "metadata": {},
   "source": [
    "accuracy 精度  = 预测正确的样本 / 总样本  = TP + TN / TP + TN + FP + FN\n",
    "\n",
    "precision 查准率 = 挑出的西瓜有多少是好西瓜 = TP / TP + FP\n",
    "\n",
    "recall 查全率 = 所有好西瓜有多少被挑出了 = TP / TP + FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf05a7",
   "metadata": {},
   "source": [
    "Q:\n",
    "\n",
    "**z-test & t-test**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270eeb30",
   "metadata": {},
   "source": [
    "Q: \n",
    "\n",
    "**Independence 独立**\n",
    "    \n",
    "Two events are independent, if the occurrence of one does not affect the probability of occurrence of the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df842162",
   "metadata": {},
   "source": [
    "Q: \n",
    "\n",
    "**Conditional Independence 条件独立**\n",
    "    \n",
    "条件独立的基本定义: \n",
    "P(F1, F2 | C) = P(F1 | C) * P(F2 | C) \n",
    "也就是说已知C条件的条件下，F1和F2是独立的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb7700",
   "metadata": {},
   "source": [
    "Q: \n",
    "\n",
    "**Bayes' Rule 贝叶斯定理**\n",
    "\n",
    "P(B|A)= P(B)* P(A|B) / P(A)\n",
    "新信息出现后B的概率 = B原先的概率*信息带来的调整\n",
    "\n",
    "P(B|A)被称作后验概率 (Posterior Probability): the likelihood of event B occurring given that A is true\n",
    "P(B)被称作先验概率 (Prior Probability)，也是单独B的概率\n",
    "P(A|B)被称作似然函数(Likelihood)，也是条件概率: the likelihood of event A occurring given that B is true\n",
    "P(A|B)P(A)被称为调整因子，使得预估概率更接近真是概率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98205b71",
   "metadata": {},
   "source": [
    "Q:  \n",
    "\n",
    "**Bernoulli and Binomial Distributions 伯努利分布和二项式分布**\n",
    "    \n",
    "i. 伯努利分布 (Bernoulli distribution),  也叫做两点分布(two-point distribution)\n",
    "伯努利试验（Bernoulli trial）是只有两种可能结果的单次随机试验.\n",
    "一次试验只有两个可能结果，即“成功”和“失败” . “成功”是指我们感兴趣的某种特征 .\n",
    "P(Y=y)=py(1-p)1-y , 0<p<1, y=0,1\n",
    "\n",
    "一个离散型随机变量X只取0和1两个可能的值\n",
    "\n",
    "ii. 二项分布 Binomial distribution\n",
    "\t二项分布即重复n次独立的伯努利试验.\n",
    "\t重复进行 n 次试验，出现“成功”的次数对应的离散型随机变量X的概率分布称为二项分布.\n",
    "P(X=x)=Cnxpxqn-x , x=0,1,2,...,n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67076470",
   "metadata": {},
   "source": [
    "Q: \n",
    "\n",
    "**Central Limit Theorem 中心极限定理**\n",
    "\n",
    "大量相互独立的随机变量，其均值（或者和）的分布以正态分布为极限（意思就是当满足某些条件的时候，比如Sample Size比较大，采样次数区域无穷大的时候，就越接近正态分布）。\n",
    "\n",
    "即样本量极大时， 样本均值的抽样分布趋近于正态分布。这和样本所属的总体的分布类型无关。\n",
    "\n",
    "中心极限定理：\n",
    "大量相互独立的随机变量，其均值（或者和）的分布以正态分布为极限（意思就是当满足某些条件的时候，比如Sample Size比较大，采样次数区域无穷大的时候，就越接近正态分布）。\n",
    "\n",
    "而这个定理最重要的地方在于，无论是什么分布的随机变量，都满足这个定理。\n",
    "\n",
    "在自然界与生产中，一些现象受到许多相互独立的随机因素的影响，如果每个因素所产生的影响都很微小时，总的影响可以看作是服从正态分布的。中心极限定理就是从数学上证明了这一现象 。最早的中心极限定理是讨论n重伯努利试验中，事件A出现的次数渐近于正态分布的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928999f7",
   "metadata": {},
   "source": [
    "Q: \n",
    "\n",
    "**Law of large numbers 大数定理**\n",
    "\n",
    "大数定律讲的是，样本量极大时，样本的均值必然趋近于总体的期望， Xn ≈ u，因此我们可以用样本均值来估计总体的期望。\n",
    "\n",
    "简单的可以描述为，如果有一个随机变量X，你不断的观察并且采样这个随机变量，得到了n个采样值，X1,X2,..., Xn，然后求得这n个采样值得平均值Xn，当n趋向于正无穷的时候，这个平均值就收敛于这个随机变量X的期望。\n",
    "\n",
    "如果有一个随机变量X，你不断的观察并且采样这个随机变量，得到了n个采样值，X1,X2,..., Xn，然后求得这n个采样值得平均值Xn，当n趋向于正无穷的时候，这个平均值就收敛于这个随机变量X的期望。\n",
    "\n",
    "在linear regression, logistic regression 都会用到"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d9e61",
   "metadata": {},
   "source": [
    "Q: \n",
    "\n",
    "**Maximum Likelihood Estimation 最大似然估计**\n",
    "\n",
    "\n",
    "极大似然估计，利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值。\n",
    "\n",
    "换句话说，极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。\n",
    "\n",
    "参数未知，通过对结果的推测得到最有可能出现的参数\n",
    "\n",
    "比其他估计方法更加简单；\n",
    "收敛性：无偏或者渐近无偏，当样本数目增加时，收敛性质会更好；\n",
    "如果假设的类条件概率模型正确，则通常能获得较好的结果。但如果假设模型出现偏差，将导致非常差的估计结果。\n",
    "\n",
    "最大似然估计的一般求解过程：\n",
    "写出似然函数；\n",
    "对似然函数取对数，并整理；\n",
    "求导数 ；\n",
    "解似然方程求最大值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc3ade",
   "metadata": {},
   "source": [
    "Q:\n",
    "\n",
    "**probability 概率**\n",
    "\n",
    "概率是在特定环境下某件事情发生的可能性，也就是结果没有产生之前依据环境所对应的参数来预测某件事情发生的可能性，概率越大说明这件事情越可能会发生。\n",
    "似然刚好相反，是在确定的结果下去推测产生这个结果的可能环境（参数），该事件在不同条件下发生的可能性，似然函数的值越大说明该事件在对应的条件下发生的可能性越大。\n",
    "\n",
    "概率：已知参数，推测结果的可能性\n",
    "概率描述的是在一定条件下某个事件发生的可能性，概率越大说明这件事情越可能会发生\n",
    "似然：参数未知，通过对结果的推测求参数\n",
    "似然描述的是结果已知的情况下，似然函数的值越大说明该事件在对应的条件下发生的可能性越大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f8cbda",
   "metadata": {},
   "source": [
    "Q:\n",
    "\n",
    "**- Discrete random variables离散随机变量**\n",
    "\n",
    "**- Continuous random variable连续随机变量**\n",
    "\n",
    "**- Probability density function (PDF)概率密度函数**\n",
    "\n",
    "**- Cumulative Distribution Functions (CDFs)累积分布函数**\n",
    "\n",
    "**- Probability Mass Function (PMF) 概率质量函数**\n",
    "\n",
    "\n",
    "\n",
    "1\n",
    "随机变量： “事件结果和数的对应关系”就形成了随机变量\n",
    "随机变量的取值：直接实验结果，或者结果映射（函数）\n",
    "随机变量的类型：离散型随机变量，或者是，连续型随机变量\n",
    "随机变量是说，某个变量的值，不是一个确定的值；但是各取值的概率分布，即各取值之可能程度的大小关系，是确定的。概括总结，第一，随机变量所有的取值是清楚的；第二，随机变量的具体取值是不确定的。\n",
    "\n",
    "随机变量一般用大写字母表示，其具体的取值一般用小写字母来表示。随机变量 X 取值为x 的概率，本质上也是一个事件的概率，这个事件就是{X=x} ，我们将他记作：\n",
    "PX(x)=P({X=x}) 。\n",
    "\n",
    "\n",
    "2\n",
    "离散型随机变量\n",
    "离散型随机变量（Discrete random variables）\n",
    "Definition:\n",
    "A discrete random variable is a random variable that has only a finite or countably infinite (think integers or whole numbers) number of possible values.\n",
    "\n",
    "如果一个随机变量的全部可能取值，只有有限多个或可数的无穷多个，则称它是离散型随机变量，比如上面的计算两个骰子点数之和。\n",
    "\n",
    "研究随机变量的方法就是穷举，由于离散型随机变量的取值可以一个个列出，故可以用分布律研究。连续情形不可一一列出，那就穷尽所有区间上的概率，分布函数恰好能够胜任。\n",
    "\n",
    "Expected Value and Variance of Discrete Random Variables:\n",
    "离散型随机变量的期望 (Expected Value) or Mean\n",
    "描述离散型随机变量取值的集中程度 \n",
    "\n",
    "离散型随机变量的方差 (Variance=The square of Standard Deviation)\n",
    "描述离散型随机变量取值的分散程度 \n",
    "\n",
    "\n",
    "离散型随机变量对应的常见分布有：\n",
    "两点分布\n",
    "二项分布\n",
    "几何分布\n",
    "超几何分布\n",
    "均匀分布\n",
    "泊松分布\n",
    "\n",
    "3\n",
    "连续型随机变量\n",
    "如果随机变量的取值为连续的（如全部实数，一段区间），则称它为连续型随机变量\n",
    "A continuous random variable is a random variable with infinitely many possible values (think an interval of real numbers, e.g., [0,1]).\n",
    "连续型随机变量对应的常见分布有：\n",
    "均匀分布\n",
    "指数分布\n",
    "正态分布\n",
    "\n",
    "\n",
    "4\n",
    "当我们使用概率函数描述连续概率分布时，我们称其为概率密度函数（probability density function），通常缩写为pdf。\n",
    "概率密度函数（probability density function）, 连续型随机变量的概率密度函数是一个描述某个确定的取值点附近的可能性的函数。\n",
    "\n",
    "5\n",
    "累积分布函数Cumulative Distribution Functions (CDFs) for Discrete Random Variables\n",
    "CDF对于离散型随机变量的定义也适用于连续型随机变量\n",
    "CDF是PDF的（从负无穷-oo到当前值的）积分，PDF是CDF的导数。\n",
    "CDF相当于其左侧的面积，也相当于小于该值的概率，负无穷的CDF值为０，正无穷的CDF值总为１。\n",
    "\n",
    "累积分布函数CDF：概率函数取值的累加结果，所以它又叫累积概率函数。对于连续随机变量来说，概率是PDF的积分，累计概率函数也就是PDF的积分，只是区间不同。\n",
    "\n",
    "6.\n",
    "概率质量函数 Probability Mass Function (PMF) \n",
    "\n",
    "概率质量函数就是将随机变量的每个值映射到其概率上。也就是说，我们可以计算理算随机变量等于一个特定值的概率。\n",
    "\n",
    "Definition·\n",
    "The probability mass function (pmf) (or frequency function) of a discrete random variable X assigns probabilities to the possible values of the random variable. More specifically, if x1,x2,… denote the possible values of a random variable X, then the probability mass function is denoted as p and we write\n",
    "f(xi)=P(X=xi)\n",
    "由于概率质量函数返回概率，所以它必须遵循概率法则（公理）。也就是说，概率质量函数输出0到1之间的值（含），而所有结果的概率质量函数输出之和等于1。\n",
    "\n",
    "\n",
    "7\n",
    "Normal Distributions\n",
    "    \n",
    "均值设为零（μ=0），标准差设为1（σ=1）\n",
    "正态分布大概是所有概率和统计学问题中最常见的分布了。它如此常见的原因之一是中心极限定理。\n",
    "使用错误的参数值会得到离你的期望相差很远的结果。\n",
    "\n",
    "8\n",
    "总结：\n",
    "概率分布是结果及相应概率的列表。\n",
    "我们可以用表格罗列小分布的结果和概率，但大分布用函数概括更方便。\n",
    "离散概率分布的表示函数称为概率质量函数 PMF\n",
    "连续概率分布的表示函数称为概率密度函数 PDF\n",
    "表示概率分布的函数同样遵循概率法则。\n",
    "概率质量函数PMF的输出是概率，概率密度函数PDF曲线下面积表示概率。\n",
    "概率函数的参数在定义随机变量结果概率上起关键作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d712b5",
   "metadata": {},
   "source": [
    "Q:\n",
    "\n",
    "**Linear Regression 线性回归**\n",
    "\n",
    "\n",
    "1.Data\n",
    "类型，来源，size，clean dataset？pre-processing，分布，分析\n",
    "数据集大，要不要抽样分析？\n",
    "2.parameters? Coefficient?\n",
    "Assumption\n",
    "Loss function / cost function\n",
    "MLE， LS\n",
    "3. Evaluation\n",
    "MSE\n",
    "Overfitting\n",
    "LASSO，Ridge\n",
    "Bias vs. Variance\n",
    "\n",
    "\n",
    "Loss function\n",
    "\n",
    "\n",
    "(1) How to measure the performance of a linear regression model?\n",
    "- use MSE to see if the model give the least error to test data,\n",
    "\n",
    "\n",
    "(2) What is MSE?\n",
    "- To calculate the difference of the predict value of the dataset, to find the average error of the prediction value\n",
    "\n",
    "\n",
    "(3) Is MSE the smaller the better?\n",
    "- Yes, the smaller the better on our testing dataset because MSE here is using for performance on testing dataset. But the model could be overfitting\n",
    "\n",
    "\n",
    "(4) when the overfitting happens?\n",
    "- Model too complex, fit perfect on training dataset, not applicable to testing dataset. Overfitting is coming when model too complex, less data\n",
    "\n",
    "\n",
    "(5) how to solve the overfitting problem?\n",
    "- 常见的：\n",
    "- 最优：regularization（主要考察）\n",
    "- Features reduction\n",
    "- Increase data\n",
    "- L1, L2 regularization, balance bias and variance , to make more stable\n",
    "\n",
    "\n",
    "(6) what’s the difference between L1 and L2?\n",
    "- 首先： 从定义\n",
    "- 其次：效果\n",
    "- L1 LASSO, not stable, two features are correlated, tend to make one feature tend to zero\n",
    "- L2, more stable, better to work on correlated features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a82426",
   "metadata": {},
   "source": [
    "Q:\n",
    "\n",
    "**Logistic Regression 逻辑回归**\n",
    "\n",
    "1.Data\n",
    "类型，来源，size，clean dataset？pre-processing，分布，分析\n",
    "数据集大，要不要抽样分析？\n",
    "\n",
    "2.parameters? Coefficient?\n",
    "Assumption\n",
    "Loss function / cost function\n",
    "MLE， LS\n",
    "\n",
    "3.Evaluation\n",
    "MSE\n",
    "Overfitting\n",
    "ROC, AUC\n",
    "Confusion matrix\n",
    "\n",
    "\n",
    "（1） Cost Function是什么?\n",
    "- argmini=1n[-yilog(h(xi))-(1-yi)log(1-h(xi))]\n",
    "\n",
    "（2） 如何interpret coefficient：\n",
    "- Logistic regression parameter represents?\n",
    "- 考察对logistic regression的定义的理解\n",
    "\n",
    "（3） 如何construct ROC curve\n",
    "- True positive rate vs. False positive rate, under different threshold\n",
    "\n",
    "（4） 如何interpret AUC？Does AUC the bigger the better? What does AUC=0.9 mean?\n",
    "\n",
    "（5） 如何estimate logistic regression的coeff\n",
    "- Maximum Likelihood Estimation\n",
    "\n",
    "(6) How does MLE works?\n",
    "\n",
    "(7) Can you write MLE for logistic regression?\n",
    "\n",
    "(8) Can you write code to do MLE?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3212e3a",
   "metadata": {},
   "source": [
    " ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f3708",
   "metadata": {},
   "source": [
    "# II. A/B testing A/B测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40607b",
   "metadata": {},
   "source": [
    "## Q10: Why do we need secondary metrics in A/B testing? 为什么在A/B测试中需要辅助指标？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec84121",
   "metadata": {},
   "source": [
    "Acquisition → Activation → Retention → Revenue\n",
    "获取→激活→留存→收入\n",
    "\n",
    "i. track long-term user experience change\n",
    "\n",
    "page bounce rate（点了又推出）; page load latency（加载延迟）; customer service calls/ messages\n",
    "\n",
    "app-install; logins; searches; high-intent page views\n",
    "\n",
    "ii. explain the revenue change\n",
    "\n",
    "sustainable revenue growth = short-term revenue growth + user experience improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b81b98",
   "metadata": {},
   "source": [
    "## Q10.1 Direct metrics vs compound metrics: 直接指标和复合指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ca762",
   "metadata": {},
   "source": [
    "i. Direct metrics: clicks, conversions, views, page bounce rate\n",
    "\n",
    "ii. Compound metrics: LTV( User lifetime value), Page performance score(Google lighthouse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4380ba",
   "metadata": {},
   "source": [
    "## Q11: Why do we need to do randomization in A/B testing? 为什么需要在 A/B 测试中进行随机化？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38736c8c",
   "metadata": {},
   "source": [
    "i. 确保randomness: 一个user进入两个group的概率是一样的，完全随机。\n",
    "\n",
    "ii. 确保单一变量控制：除experiment effect之外，两个group所有feature完全一样。\n",
    "\n",
    "确保上述两个条件的构造实验过程，叫做create counterfactual. \n",
    "\n",
    "—> 只有通过设计randomized experiment, 确保randomness和单一变量控制，才能证明因果关系causal effect。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f92807",
   "metadata": {},
   "source": [
    "## Q12: How to do randomization?/ Given a random number generation between 0 and 1, how to implement the randomization process in A/B testing? 如何随机化？如果一个在[0, 1]随机值，如何在A/B测试中执行随机化过程？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7f9df9",
   "metadata": {},
   "source": [
    "利用unique identifier生成一个随机数，然后将这个随机数映射到[0,1]之间，再进行上述处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042d6a53",
   "metadata": {},
   "source": [
    "## Q13: Why do we usually set the same sample sizes in the treatment & control group? 为什么在对照组和控制组中设置相同的样本量？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58274436",
   "metadata": {},
   "source": [
    "因为在total sample size (m+n) 一定的前提下，当m = n时，two sample test得到的test statistics绝对值最大，假设检验的结果更容易显著(significant)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caefa614",
   "metadata": {},
   "source": [
    "## Q14: How to test if the treatment control group assignment is randomized? 如何测试如果对照组和控制组分配是否随机？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013bdf0e",
   "metadata": {},
   "source": [
    "run A/A test first. \n",
    "\n",
    "A/A test: 对treatment group 不施加treatment effect. 实验结果应是两个groups没有显著区别。\n",
    "\n",
    "用A/A test来检测allocation操作是否有bias。\n",
    "\n",
    "• A/A experiment. Compare people seeing the same thing to each other. See if the metric picks up the difference between the two. Any differences that you measure are due to the underlying variability, maybe of your system, of the user population, what users are doing, etc.\n",
    "\n",
    "【matching, holdout group, segmentation】"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0723e43c",
   "metadata": {},
   "source": [
    "## Q15: What can we do if we realize the treatment control group assignment was not randomized after the data collection, i.e. impression process, has been finished? 如果在数据收集（如impression process）完成后，意识到控制组对照组的分配不是随机的，怎么办？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0b842c",
   "metadata": {},
   "source": [
    "segmentation：在metric calculation的时候，把数据按照有问题的feature分成subgroup，然后做weighted average。\n",
    "\n",
    "avg_clicks = female_weights * female_group_avg_clicks + male_weights * male_group_avg_clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc966fa",
   "metadata": {},
   "source": [
    "## Q16: What’s the relationship between A/B testing sample size and the sample data variance? 关于A/B测试样本量和样本数据方差的关系是？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3dae4d",
   "metadata": {},
   "source": [
    "if sample variance is larger, need larger sample size.\n",
    "\n",
    "if desired effect size is smaller, need larger sample size.\n",
    "\n",
    "if desired power is larger(or desired type II error rate is smaller), need larger sample size. \n",
    "\n",
    "if desired type I error rate is smaller, need larger sample size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305195a",
   "metadata": {},
   "source": [
    "## Q17: Metrics in A/B testing are significantly positive (negative) at the beginning, but become neutral later. What’s the possible reason? A/B测试指标开始状态时显著，但之后不再显著，原因可能是？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399676e6",
   "metadata": {},
   "source": [
    "positive: novelty effect（novelty effect: users welcome changes）\n",
    "\n",
    "negative: primacy effect. （primacy effect: users are reluctant to change.）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e7953",
   "metadata": {},
   "source": [
    "## Q18: How to reduce the novelty effect in A/B testing? 如何减少A/B测试的新奇效应？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e23ef2",
   "metadata": {},
   "source": [
    "1）把实验运行久一点\n",
    "\n",
    "2）避免在单个实验引入过多或过于剧烈的改动\n",
    "\n",
    "3）在enrollment阶段，只把new visitors加入到实验中\n",
    "\n",
    "4）在analysis阶段，把new visitors和old visitors的treatment effect分开讨论"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f078760",
   "metadata": {},
   "source": [
    "## Q19: How to reduce the primary effect in A/B testing? 如何减少A/B测试的首位效应？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd00c7",
   "metadata": {},
   "source": [
    "## Q20: How to resolve interference between treatment and control group? 如何解决控制组和对照组之间的干涉？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df574ce",
   "metadata": {},
   "source": [
    "spillover between control and treatment group will impact A/B testing result.\n",
    "\n",
    "2 types of interference: \n",
    "\n",
    "① network effect网络效应: underestimate the treatment effect. \n",
    "\n",
    "② limited resource in two-sided markets: overestimate the treatment effect.\n",
    "\n",
    "\n",
    "resolve interference using different allocation strategies: \n",
    "\n",
    "i. network effect: network-based clustering\n",
    "\n",
    "ii. two-sided market: geo-based clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd86a36",
   "metadata": {},
   "source": [
    "## Q21: Analyze A/B testing result: 分析A/B测试结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38466c06",
   "metadata": {},
   "source": [
    "i. In the control group, we collected the app-usage-time of 1010 users {x1, x2,…, x10}, its sample mean value is 1 hour/day\n",
    "\n",
    "ii. In the treatment group, we collected the app-usage-time of 990 users {y1, y2, … y990}, its sample mean value is 1.2 hour/day\n",
    "\n",
    "Suppose their sample variances are the same σ^2 = 1. Can you tell which group has a longer app-usage time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c67bd5",
   "metadata": {},
   "source": [
    "Q22: Power Analysis功效分析:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddefb72c",
   "metadata": {},
   "source": [
    "在enrollment中，需要估算sample size，从而计算实验需要运行的时长。\n",
    "\n",
    "power analysis is to estimate the minimum sample size (n) required an a/b testing experiment, given a desired significance level α, effect size, and statistical power(1 - β)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a124bfc",
   "metadata": {},
   "source": [
    "Q: Effect size效果量:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a350dd7",
   "metadata": {},
   "source": [
    "the mean difference between two groups in the unit of population standard deviation\n",
    "\n",
    "ES = |μ1 - μ0| / σ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a1925",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75df3943",
   "metadata": {},
   "source": [
    "# III. Machine Learning 机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cfa00e",
   "metadata": {},
   "source": [
    "## Q1: When and why do we need to do feature normalization? 何时以及为什么需要进行特征标准化？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30fa8fe",
   "metadata": {},
   "source": [
    "值间差异大，避免值大变量weight大。\n",
    "\n",
    "feature scaling is helpful when one feature is much larger (or smaller) than another feature. \n",
    "\n",
    "Its main purpose is to standardize the values of different features.\n",
    "\n",
    "feature normalization is useful when the dataset has different feature scales, avoiding weight bias, require optimization algorithms(gradient descent, are sensitive to the input feature scales).\n",
    "\n",
    "eg. the house size could be 2000, #of bedrooms is [1,5] when predict house price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b7877",
   "metadata": {},
   "source": [
    "## Q2: Why do we usually use squared loss as the loss function of ordinary linear regression? 为什么通常使用平方损失作为普通线性回归的损失函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa5b8d4",
   "metadata": {},
   "source": [
    "1）Convexity: The squared loss function is convex, which means it has a single global minimum. This property makes it easier to find the optimal solution using optimization techniques like gradient descent. The convexity ensures that the optimization process converges to a unique solution.\n",
    "\n",
    "2）Sensitivity to outliers: The squared loss function penalizes large errors more than linear or absolute loss functions. Consequently, it is more sensitive to outliers in the data. This sensitivity can be beneficial when outliers are considered as significant deviations from the underlying linear relationship and should have a larger impact on the model.\n",
    "\n",
    "3）Maximum likelihood estimation: When the errors in the linear regression model follow a Gaussian (normal) distribution, minimizing the squared loss is equivalent to maximizing the likelihood of the observed data. This connection to maximum likelihood estimation provides a statistical interpretation for using squared loss in linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23e5c7",
   "metadata": {},
   "source": [
    "## Q3: What’s the difference and correlation between ordinary linear regression and logistics regression? 普通线性回归和逻辑回归有什么区别和联系？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a0d2d1",
   "metadata": {},
   "source": [
    "i. 同属generilized linear regression例子\n",
    "\n",
    "ii. Linear Regression\n",
    "\n",
    "① Y|X 服从Normal Distribution，\n",
    "\n",
    "② 直线，predicting continuous values\n",
    "\n",
    "③ g(E(Y|X)) = Xβ ; g() 是identity function, 即它自己\n",
    "\n",
    "ii. Logistic Regression\n",
    "\n",
    "① Y|X 服从Bernoulli Distribution，\n",
    "\n",
    "② 曲线，predicting probabilities and making binary/ categorical classifications\n",
    "\n",
    "③ g(E(Y|X)) = Xβ；g() 是logitfunction, 反函数是g^-1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b8c618",
   "metadata": {},
   "source": [
    "## Q4: What’s the probabilistic assumption of ordinary linear regression? 普通线性回归的概率假设是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e63ef1",
   "metadata": {},
   "source": [
    "normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2daa65",
   "metadata": {},
   "source": [
    "## Q5: What’s the loss function of logistic regression? 逻辑回归的损失函数是多少？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f93956",
   "metadata": {},
   "source": [
    "## Q6: What’s the probabilistic assumption of logistic regression? 逻辑回归的概率假设是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd8af9",
   "metadata": {},
   "source": [
    "bernoulli distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab2b54",
   "metadata": {},
   "source": [
    "## Q7: How to deal with a multi-class classification problem? 如何处理多类分类问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e794c90",
   "metadata": {},
   "source": [
    "cross entropy loss在binary classification和multi-class classification中都可以应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c514d24",
   "metadata": {},
   "source": [
    "## Q8: What's the trend of testing error and training eroor when we increase the model complexity? 当增加模型复杂度时，测试误差和训练误差的趋势是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b9f6c",
   "metadata": {},
   "source": [
    "## Q9: What is overfitting? 什么是过拟合？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c996a6d",
   "metadata": {},
   "source": [
    "i. overfit: when a model fits the training data well but does not work well with new examples that are not in the training set. \n",
    "\n",
    "model too closely to training dataset, fail to fit test dataset or predict future observation reliably.\n",
    "\n",
    "if have too many features, the model may fit the training set well, but almost too well and have high variance. 每次新的test dataset 都和真实值有较大偏差。\n",
    "\n",
    "ii. underfit: too few features, it underfits and has bias. \n",
    "\n",
    "iii. just right: use the model to predict outcomes correctly for new examples. generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc0068a",
   "metadata": {},
   "source": [
    "## Q9.1：What’s the general strategies to reduce model overfitting? 减少模型过拟合的通用策略是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c62a26",
   "metadata": {},
   "source": [
    "i. more training date 增加训练数据量\n",
    "\n",
    "ii. improve model formula 改进模型结构：\n",
    "\n",
    "a. use fewer features 减少Feature个数 eg. feature selection, PCA\n",
    "\n",
    "b. 改进loss function形式: 正则化 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656cdbdc",
   "metadata": {},
   "source": [
    "## Q9.2 Bias& Variance: What is bias and variance? What is bias and variance trade off? 偏差和方差：什么是偏差和方差？ 什么是偏差和方差的权衡？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044b4b26",
   "metadata": {},
   "source": [
    "Bias: model space中多个模型的平均输出结果与真实值相比的差距。即整个model space的平均准确性。\n",
    "\n",
    "Variance: model space中某个model输出结果与model space平均水平的差距的期望。\n",
    "\n",
    "Model Error = Bias^2 + Variance + σ^2\n",
    "\n",
    "Squared Error: Bias^2 + Variance\n",
    "\n",
    "underfit: 模型与training set不准，bias大\n",
    "\n",
    "overfit:模型与test set不准，variance大"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba5fc06",
   "metadata": {},
   "source": [
    "## Q10: What’s L1 regularization and L2 regularization? 什么是L1正则化和L2正则化？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9866cf",
   "metadata": {},
   "source": [
    "## Q11: What’s the difference between L1 regularization and L2 regularization? L1正则化和L2正则化有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ae7b8",
   "metadata": {},
   "source": [
    "## Q12: How to find the optimal value of hyper-parameter in the regularization term? 如何找到正则化项中超参数的最优值？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd850e3c",
   "metadata": {},
   "source": [
    "## Q13: How to prioritize precision and recall metrics in different use cases? 如何在不同的用例中确定准确率和召回率指标的优先级？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33da9d30",
   "metadata": {},
   "source": [
    "## Q14: How to explain AUC from a probability perspective? 如何从概率角度解释AUC？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e9b49",
   "metadata": {},
   "source": [
    "## Q29: How to deal with categorical features at the feature transformation stage? 特征转换阶段如何处理分类特征？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deabfe",
   "metadata": {},
   "source": [
    "## Q30: What are the common dimensionality reduction methods? 常见的降维方法有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143cfee5",
   "metadata": {},
   "source": [
    "## Q15: How to reduce overfitting of decision tree models? 如何减少决策树模型的过拟合？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be759db",
   "metadata": {},
   "source": [
    "## Q16: Why do u consider a decision tree as a non-linear model? 为什么将决策树视为非线性模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffdcba0",
   "metadata": {},
   "source": [
    "## Q17: Can tree-based models work well with sparse features? Why? 基于树的模型可以很好地处理稀疏特征吗？ 为什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920ad6d",
   "metadata": {},
   "source": [
    "## Q18: Why do random forest models usually provide better result than decision tree models? 为什么随机森林模型通常比决策树模型提供更好的结果？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f997c7e",
   "metadata": {},
   "source": [
    "## Q19: How to tune hyper-parameters in random forest models? 如何调整随机森林模型中的超参数？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec2a55",
   "metadata": {},
   "source": [
    "## Q20: What does the feature importance mean in random forest models and boosting models? 特征重要性在随机森林模型和提升方法模型中意味着什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2fab1",
   "metadata": {},
   "source": [
    "## Q21: What’s the difference between bagging methods and boosting methods? bagging 方法和 boosting 方法有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e30df8",
   "metadata": {},
   "source": [
    "## Q22: Compare the advantages and disadvantages of decision tree, random forest and GBDT. 比较决策树、随机森林和GBDT的优缺点。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecdf2c2",
   "metadata": {},
   "source": [
    "## Q23: Compare the difference between XGBoost and GBDT. 比较一下XGBoost和GBDT的区别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c9ed8",
   "metadata": {},
   "source": [
    "## Q33: What’s the difference between batch gradient descent and stochastic gradient descent? 批量梯度下降和随机梯度下降有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58444956",
   "metadata": {},
   "source": [
    "## Q24: What’s the time complexity of K-nearest neighbor? Can u further improve its time complexity with approximation methods? K近邻算法的时间复杂度是多少？ 能用近似方法进一步提升时间复杂度吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72788339",
   "metadata": {},
   "source": [
    "## Q25: What are the factors that influence performance of the K-means algorithms? 影响K-means算法性能的因素有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dc5e74",
   "metadata": {},
   "source": [
    "## Q26: How to find the optimal K for K-means algorithms? 如何找到 K-means 算法的最优 K？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc17963",
   "metadata": {},
   "source": [
    "## Q27: What to optimize centroids selection for K-means algorithm? 如何优化k均值聚类算法的质心选择？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c780fef9",
   "metadata": {},
   "source": [
    "## Q31: Describe the process of PCA. 描述PCA的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db58c4e",
   "metadata": {},
   "source": [
    "## Q32: Why do we need feature normalization during Principal Component Analysis? 主成分分析时为什么需要特征归一化？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5de61",
   "metadata": {},
   "source": [
    "## Q28: What are the common techniques to fill missing values? 填补缺失值的常用技术有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d16dd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65168a3f",
   "metadata": {},
   "source": [
    "# IV. Deep Learning 深度学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553b5fd4",
   "metadata": {},
   "source": [
    "## Q34: What’s the difference between backpropagation and gradient descent? 反向传播和梯度下降有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60fcc3",
   "metadata": {},
   "source": [
    "## Q35: Why is backpropagation more efficient than forward-pass-only gradient calculation? 为什么反向传播比仅前向传播的梯度计算更有效？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35609f9b",
   "metadata": {},
   "source": [
    "## Q36: How to train your neural network model with multiple machines? 如何用多台机器训练神经网络模型？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8146f",
   "metadata": {},
   "source": [
    "## Q37: What’s the difference between batch and epoch? 批次和周期的不同是？\n",
    "Epoch由一个或多个Batch组成, 具有一批的Epoch称为批量梯度下降学习算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24228182",
   "metadata": {},
   "source": [
    "## Q38: What is the dying ReLu problem? 什么是Relu神经元死亡问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0a15f",
   "metadata": {},
   "source": [
    "## Q39: How to reduce the overfitting problem in Neural Network Models? 如何减少神经网络模型中的过拟合问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0830dba",
   "metadata": {},
   "source": [
    "## Q40: What are the common techniques to reduce the gradient vanishing/ exploding problem? 关于减少梯度消失/梯度爆炸问题的常用技术有哪些？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120da121",
   "metadata": {},
   "source": [
    "## Q41: What’s the difference between kernel and filter in Convolutional Neural Network? 卷积神经网络中的内核和过滤器有什么区别？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aaa028",
   "metadata": {},
   "source": [
    "## Q42: What’s the difference process of doing backpropagation in a Recurrent Neural Network? 在循环神经网络中进行反向传播的过程有什么不同？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa33b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
